{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P97V05CMLvTK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Load and preprocess the data\n",
        "data = pd.read_csv('google_stock_data.csv')\n",
        "data = data['open'].values.reshape(-1, 1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "# Define a function to create sequences for RNN\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "sequence_length = 10\n",
        "X, y = create_sequences(data, sequence_length)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(X) * split_ratio)\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "train_loss = model.evaluate(X_train, y_train)\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(f'Training Loss: {train_loss:.4f}')\n",
        "print(f'Testing Loss: {test_loss:.4f}')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions and actual values\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "\n",
        "# Plot the actual vs. predicted stock prices\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test, label='Actual Stock Price', color='b')\n",
        "plt.plot(predictions, label='Predicted Stock Price', color='r')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3I4R3S3NX3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjsH4keCNaJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GmJ2F_OqNat4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}